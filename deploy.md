# ğŸš€ Guide de DÃ©ploiement Helpdeskly

## ğŸ“‹ Architecture ComplÃ¨te

L'application Helpdeskly est composÃ©e de :

- **Control API** (6500) : Gestion des tenants et authentification
- **App API** (6501) : Gestion des tickets multi-tenant
- **PostgreSQL** : Base de donnÃ©es principale + bases tenants
- **Redis** : Cache et sessions
- **PgBouncer** : Pool de connexions
- **PgAdmin** : Interface d'administration

---

## ğŸ”§ Configuration Environnement

### ğŸ“„ Fichier `.env.production`

```bash
# ================== Environment ==================
NODE_ENV=production

# PORT
CONTROL_PORT=6500
APP_PORT=6501
FRONTEND_URL=https://app.votre-domaine.com

# ================== Control API ==================
CONTROL_DATABASE_URL=postgresql://helpdeskly_user:${CONTROL_DB_PASSWORD}@postgres:5432/helpdeskly_control

# ================== Tenant Database Template ==================
DATABASE_URL=postgresql://helpdeskly_user:${TENANT_DB_PASSWORD}@postgres:5432/postgres

# JWT Configuration (âš ï¸ CHANGEZ EN PRODUCTION!)
JWT_SECRET=votre-clÃ©-super-secrÃ¨te-production-minimum-32-caractÃ¨res-2024
JWT_EXPIRES_IN=15m
JWT_EXPIRES_IN_SECONDS=900
JWT_ISSUER=helpdeskly-prod
JWT_AUDIENCE=helpdeskly-users-prod

# Refresh Token Configuration
REFRESH_TOKEN_DAYS=7

# Security
BCRYPT_ROUNDS=12

# ================== Redis ==================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_URL=redis://redis:6379

# ================== Security ==================
DB_ENCRYPTION_KEY="votre-clÃ©-secrÃ¨te-db-encryption-32chars-prod"

# ================== Monitoring ==================
LOG_LEVEL=info
ENABLE_METRICS=true
ENABLE_SWAGGER=false

# ================== Database Credentials ==================
POSTGRES_USER=helpdeskly_user
POSTGRES_PASSWORD=super_secure_password_2024
CONTROL_DB_PASSWORD=control_db_secure_password_2024
TENANT_DB_PASSWORD=tenant_db_secure_password_2024

# ================== CORS ==================
CORS_ORIGINS=https://app.votre-domaine.com,https://admin.votre-domaine.com
```

---

## ğŸ³ Docker Compose Production

### ğŸ“„ `docker-compose.prod.yml`

```yaml
version: "3.9"

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ—„ï¸ INFRASTRUCTURE DATABASE
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  postgres:
    image: postgres:16-alpine
    container_name: helpdeskly-postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db-prod.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - helpdeskly-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Base pour migrations initiales (optionnelle en prod)
  postgres_migrations:
    image: postgres:16-alpine
    container_name: helpdeskly-postgres-migrations
    restart: "no"
    ports:
      - "5436:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: postgres
    networks:
      - helpdeskly-network

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ”— PGBOUNCER - Connection Pooling
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  pgbouncer:
    image: edoburu/pgbouncer:latest
    container_name: helpdeskly-pgbouncer
    restart: unless-stopped
    ports:
      - "6432:6432"
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/postgres
      AUTH_USER: ${POSTGRES_USER}
      AUTH_PASSWORD: ${POSTGRES_PASSWORD}
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 1000
      DEFAULT_POOL_SIZE: 25
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - helpdeskly-network

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ”´ REDIS - Cache & Sessions
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  redis:
    image: redis:7-alpine
    container_name: helpdeskly-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - helpdeskly-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ›ï¸ APIS HELPDESKLY
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  # Control API - Gestion des tenants
  control-api:
    build:
      context: .
      dockerfile: Dockerfile
      target: control-api
    container_name: helpdeskly-control-api
    restart: unless-stopped
    ports:
      - "6500:6500"
    environment:
      NODE_ENV: production
      PORT: 6500
      CONTROL_DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/helpdeskly_control
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN}
      JWT_ISSUER: ${JWT_ISSUER}
      JWT_AUDIENCE: ${JWT_AUDIENCE}
      REDIS_URL: redis://redis:6379
      BCRYPT_ROUNDS: ${BCRYPT_ROUNDS}
      LOG_LEVEL: ${LOG_LEVEL}
      ENABLE_SWAGGER: ${ENABLE_SWAGGER}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - helpdeskly-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6500/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # App API - Gestion des tickets
  app-api:
    build:
      context: .
      dockerfile: Dockerfile
      target: app-api
    container_name: helpdeskly-app-api
    restart: unless-stopped
    ports:
      - "6501:6501"
    environment:
      NODE_ENV: production
      PORT: 6501
      CONTROL_DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/helpdeskly_control
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/postgres
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN}
      JWT_ISSUER: ${JWT_ISSUER}
      JWT_AUDIENCE: ${JWT_AUDIENCE}
      REDIS_URL: redis://redis:6379
      DB_ENCRYPTION_KEY: ${DB_ENCRYPTION_KEY}
      LOG_LEVEL: ${LOG_LEVEL}
      ENABLE_SWAGGER: ${ENABLE_SWAGGER}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      control-api:
        condition: service_healthy
    networks:
      - helpdeskly-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6501/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ› ï¸ OUTILS D'ADMINISTRATION
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  # PgAdmin - Interface d'administration BDD
  pgadmin:
    image: dpage/pgadmin4:8
    container_name: helpdeskly-pgadmin
    restart: unless-stopped
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@helpdeskly.local
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin_secure_password_2024}
      PGADMIN_LISTEN_PORT: 80
      PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION: "True"
      PGADMIN_CONFIG_CONSOLE_LOG_LEVEL: 30
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - ./pgadmin/servers.json:/pgadmin4/servers.json:ro
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - helpdeskly-network
    profiles:
      - tools # Utilise 'docker-compose --profile tools up' pour inclure

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸŒ REVERSE PROXY NGINX
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  nginx:
    image: nginx:alpine
    container_name: helpdeskly-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    depends_on:
      control-api:
        condition: service_healthy
      app-api:
        condition: service_healthy
    networks:
      - helpdeskly-network
    profiles:
      - proxy

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ VOLUMES PERSISTANTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  pgadmin_data:
    driver: local

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ RÃ‰SEAUX
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

networks:
  helpdeskly-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

---

## ğŸ³ Dockerfile Multi-Stage

### ğŸ“„ `Dockerfile`

```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ï¸ DOCKERFILE MULTI-STAGE PRODUCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Stage 1: Builder
FROM node:20-alpine AS builder

WORKDIR /app

# Installation de pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

# Copier les fichiers de configuration
COPY package.json pnpm-lock.yaml ./
COPY apps/control-api/package.json ./apps/control-api/
COPY apps/app-api/package.json ./apps/app-api/

# Copier les configurations
COPY tsconfig.json nest-cli.json ./
COPY prisma ./prisma

# Installer toutes les dÃ©pendances
RUN pnpm install --frozen-lockfile

# Copier le code source
COPY . .

# GÃ©nÃ©rer les clients Prisma
RUN pnpm exec prisma generate --schema=./prisma/control/schema.prisma
RUN pnpm exec prisma generate --schema=./prisma/tenant/schema.prisma

# Build les deux applications
RUN pnpm --filter control-api build
RUN pnpm --filter app-api build

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ›ï¸ STAGE PRODUCTION: CONTROL API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FROM node:20-alpine AS control-api

WORKDIR /app

# Installation de curl pour health checks
RUN apk add --no-cache curl

# Installation de pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

# CrÃ©er un utilisateur non-root
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nestjs -u 1001

# Copier les fichiers nÃ©cessaires depuis le builder
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/prisma ./prisma
COPY --from=builder --chown=nestjs:nodejs /app/package.json ./

# Variables d'environnement
ENV NODE_ENV=production
ENV PORT=6500

# Changer vers l'utilisateur non-root
USER nestjs

# Port d'exposition
EXPOSE 6500

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:6500/health || exit 1

# Commande de dÃ©marrage
CMD ["node", "dist/apps/control-api/main"]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ« STAGE PRODUCTION: APP API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FROM node:20-alpine AS app-api

WORKDIR /app

# Installation de curl pour health checks
RUN apk add --no-cache curl

# Installation de pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

# CrÃ©er un utilisateur non-root
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nestjs -u 1001

# Copier les fichiers nÃ©cessaires depuis le builder
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/prisma ./prisma
COPY --from=builder --chown=nestjs:nodejs /app/package.json ./

# Variables d'environnement
ENV NODE_ENV=production
ENV PORT=6501

# Changer vers l'utilisateur non-root
USER nestjs

# Port d'exposition
EXPOSE 6501

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:6501/health || exit 1

# Commande de dÃ©marrage
CMD ["node", "dist/apps/app-api/main"]
```

---

## ğŸŒ Configuration Nginx

### ğŸ“„ `nginx/nginx.conf`

```nginx
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logs
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=5r/s;

    # Upstreams
    upstream control-api {
        server control-api:6500;
    }

    upstream app-api {
        server app-api:6501;
    }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ›ï¸ CONTROL API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    server {
        listen 80;
        server_name control-api.votre-domaine.com;

        # Rate limiting plus strict pour l'auth
        limit_req zone=auth burst=10 nodelay;

        # Headers de sÃ©curitÃ©
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;

        location / {
            proxy_pass http://control-api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # Health check endpoint
        location /health {
            proxy_pass http://control-api/health;
            access_log off;
        }
    }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ« APP API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    server {
        listen 80;
        server_name app-api.votre-domaine.com;

        # Rate limiting
        limit_req zone=api burst=20 nodelay;

        # Headers de sÃ©curitÃ©
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;

        location / {
            proxy_pass http://app-api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # Health check endpoint
        location /health {
            proxy_pass http://app-api/health;
            access_log off;
        }
    }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ› ï¸ PGADMIN (Optionnel)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    server {
        listen 80;
        server_name pgadmin.votre-domaine.com;

        # Restriction d'accÃ¨s (remplacez par vos IPs)
        # allow 192.168.1.0/24;
        # deny all;

        location / {
            proxy_pass http://pgadmin:80;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

---

## ğŸ“„ Scripts de DÃ©ploiement

### ğŸ“„ `scripts/deploy.sh`

```bash
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ SCRIPT DE DÃ‰PLOIEMENT PRODUCTION HELPDESKLY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

# Variables
ENVIRONMENT=${1:-production}
VERSION=$(git rev-parse --short HEAD)
COMPOSE_FILE="docker-compose.prod.yml"

echo "ğŸš€ DÃ©ploiement Helpdeskly ${ENVIRONMENT}"
echo "ğŸ“‹ Version: ${VERSION}"
echo "ğŸ“‹ Compose: ${COMPOSE_FILE}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” VÃ‰RIFICATIONS PRÃ‰-DÃ‰PLOIEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ” VÃ©rifications prÃ©-dÃ©ploiement..."

# VÃ©rifier les fichiers requis
REQUIRED_FILES=(".env.${ENVIRONMENT}" "docker-compose.prod.yml" "Dockerfile")
for file in "${REQUIRED_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        echo "âŒ Fichier manquant: $file"
        exit 1
    fi
done

# VÃ©rifier Docker
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker n'est pas installÃ©"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker Compose n'est pas installÃ©"
    exit 1
fi

echo "âœ… VÃ©rifications rÃ©ussies"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TESTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ§ª ExÃ©cution des tests..."
pnpm test || {
    echo "âŒ Tests Ã©chouÃ©s - ArrÃªt du dÃ©ploiement"
    exit 1
}
echo "âœ… Tests rÃ©ussis"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ï¸ BUILD DES IMAGES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ—ï¸ Build des images Docker..."

# Build avec cache
docker build --target control-api -t helpdeskly/control-api:${VERSION} .
docker build --target app-api -t helpdeskly/app-api:${VERSION} .

# Tag latest
docker tag helpdeskly/control-api:${VERSION} helpdeskly/control-api:latest
docker tag helpdeskly/app-api:${VERSION} helpdeskly/app-api:latest

echo "âœ… Images buildÃ©es avec succÃ¨s"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—„ï¸ MIGRATIONS BASE DE DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ—„ï¸ Migrations des bases de donnÃ©es..."

# DÃ©marrer seulement postgres pour les migrations
docker-compose -f ${COMPOSE_FILE} up -d postgres
sleep 10

# Migration Control DB
echo "ğŸ“Š Migration Control Database..."
docker-compose -f ${COMPOSE_FILE} run --rm control-api \
    npx prisma migrate deploy --schema=prisma/control/schema.prisma

echo "âœ… Migrations terminÃ©es"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš¢ DÃ‰PLOIEMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸš¢ DÃ©ploiement des services..."

# DÃ©ploiement avec zÃ©ro downtime
docker-compose -f ${COMPOSE_FILE} up -d --remove-orphans

echo "â³ Attente du dÃ©marrage des services..."
sleep 30

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¥ HEALTH CHECKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ¥ VÃ©rification de la santÃ© des services..."

# Function pour health check avec retry
check_health() {
    local url=$1
    local service_name=$2
    local max_attempts=5
    local attempt=1

    while [ $attempt -le $max_attempts ]; do
        if curl -f --silent --max-time 10 "${url}" > /dev/null; then
            echo "âœ… ${service_name}: OK"
            return 0
        fi
        echo "â³ ${service_name}: Tentative ${attempt}/${max_attempts}..."
        sleep 10
        ((attempt++))
    done

    echo "âŒ ${service_name}: Ã‰CHEC aprÃ¨s ${max_attempts} tentatives"
    return 1
}

# Health checks
check_health "http://localhost:6500/health" "Control API"
check_health "http://localhost:6501/health" "App API"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§¹ NETTOYAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ§¹ Nettoyage des images orphelines..."
docker image prune -f

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ‰ SUCCÃˆS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo ""
echo "ğŸ‰ DÃ©ploiement terminÃ© avec succÃ¨s!"
echo ""
echo "ğŸ“Š URLs des services:"
echo "ğŸ›ï¸  Control API: http://localhost:6500"
echo "ğŸ«  App API: http://localhost:6501"
echo "ğŸ—„ï¸  PgAdmin: http://localhost:5050 (avec --profile tools)"
echo ""
echo "ğŸ“‹ Version dÃ©ployÃ©e: ${VERSION}"
echo "ğŸ“‹ Logs: docker-compose -f ${COMPOSE_FILE} logs -f"
```

### ğŸ“„ `scripts/rollback.sh`

```bash
#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â†©ï¸ SCRIPT DE ROLLBACK
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -e

PREVIOUS_VERSION=${1}
COMPOSE_FILE="docker-compose.prod.yml"

if [ -z "$PREVIOUS_VERSION" ]; then
    echo "âŒ Usage: ./rollback.sh <previous_version>"
    echo "ğŸ’¡ Exemple: ./rollback.sh abc123"
    exit 1
fi

echo "â†©ï¸ Rollback vers la version: ${PREVIOUS_VERSION}"

# VÃ©rifier que l'image existe
if ! docker image inspect helpdeskly/control-api:${PREVIOUS_VERSION} >/dev/null 2>&1; then
    echo "âŒ Image helpdeskly/control-api:${PREVIOUS_VERSION} introuvable"
    exit 1
fi

# Tag des images previous vers latest
docker tag helpdeskly/control-api:${PREVIOUS_VERSION} helpdeskly/control-api:latest
docker tag helpdeskly/app-api:${PREVIOUS_VERSION} helpdeskly/app-api:latest

# RedÃ©ploiement
docker-compose -f ${COMPOSE_FILE} up -d --force-recreate control-api app-api

echo "âœ… Rollback terminÃ© vers ${PREVIOUS_VERSION}"
```

---

## ğŸš€ Commandes de DÃ©ploiement

### DÃ©veloppement Local

```bash
# DÃ©marrer tous les services de dÃ©veloppement
docker-compose up -d

# DÃ©marrer seulement l'infrastructure
docker-compose up -d postgres redis pgbouncer

# DÃ©marrer avec PgAdmin
docker-compose --profile tools up -d
```

### Production

```bash
# DÃ©ploiement complet
chmod +x scripts/deploy.sh
./scripts/deploy.sh production

# DÃ©ploiement avec Nginx
docker-compose --profile proxy up -d

# Monitoring des logs
docker-compose -f docker-compose.prod.yml logs -f

# Rollback
./scripts/rollback.sh abc123
```

### Maintenance

```bash
# Backup base de donnÃ©es
docker exec helpdeskly-postgres pg_dump -U helpdeskly_user helpdeskly_control > backup.sql

# Monitoring des performances
docker stats

# Nettoyage
docker system prune -a -f
```

---

## ğŸ“Š Monitoring et MÃ©triques

### Health Checks Disponibles

- **Control API**: `http://localhost:6500/health`
- **App API**: `http://localhost:6501/health`
- **PostgreSQL**: Automatique via Docker
- **Redis**: Automatique via Docker

### Logs CentralisÃ©s

```bash
# Tous les services
docker-compose logs -f

# Service spÃ©cifique
docker-compose logs -f control-api
docker-compose logs -f app-api
```

---

## ğŸ”’ SÃ©curitÃ© Production

### âœ… Checklist SÃ©curitÃ©

- [ ] **JWT_SECRET** changÃ© en production
- [ ] **Mots de passe DB** sÃ©curisÃ©s
- [ ] **CORS** configurÃ© correctement
- [ ] **Rate limiting** activÃ©
- [ ] **HTTPS** configurÃ© (via reverse proxy)
- [ ] **Headers de sÃ©curitÃ©** ajoutÃ©s
- [ ] **Swagger** dÃ©sactivÃ© en production
- [ ] **Logs** configurÃ©s niveau INFO
- [ ] **Backups** automatisÃ©s
- [ ] **Monitoring** mis en place

\*\*ğŸ¯ Ton application multi-tenant est maintenant prÃªte pour la production
